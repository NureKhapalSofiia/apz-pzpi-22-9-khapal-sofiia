Міністерство освіти і науки України
Харківський національний університет радіоелектроніки
Кафедра програмної інженерії









Звіт
з лабораторної роботи №4
з дисципліни «Архітектура програмного забезпечення»








Виконала:                                                                             Перевірив:
ст. гр. ПЗПІ-22-9                                                                 Дашенков Д.С.
Хапаль С.Є.

Харків 2025

Тема: Масштабування бекенда
Мета: провести масштабування бекенда

- Опис стратегії масштабування системи
	У проєкті була реалізована стратегія масштабування бекенд-системи з використанням інструментів Kubernetes. Масштабування здійснюється для забезпечення стабільної роботи застосунку при зростанні кількості користувачів і підвищенні навантаження на сервер.
Обрана стратегія — горизонтальне масштабування. Вона передбачає збільшення кількості pod'ів (екземплярів застосунку), які одночасно обробляють запити. Це дозволяє системі рівномірно розподіляти навантаження та уникати перевантаження окремих компонентів.
Для доступу до сервісу використовувався Service типу LoadBalancer, який автоматично балансує трафік між усіма активними pod'ами.
- Опис технічних рішень які роблять масштабування можливим
Для забезпечення масштабування системи було застосовано низку технічних рішень. Основою є контейнеризація застосунку за допомогою Docker, що дозволяє запускати бекенд у вигляді незалежного образу в будь-якому середовищі. Далі, для оркестрації використовується Kubernetes, який автоматизує керування подами, їх розгортанням і відновленням у разі збоїв. Масштабування досягається шляхом зміни кількості реплік у Deployment, а саме за допомогою команди kubectl scale deployment skinora-backend --replicas=2/3/….
Також застосовується LoadBalancer-сервіс, що дозволяє рівномірно розподіляти трафік між усіма активними подами. Завдяки стейтлес-архітектурі (відсутність збереження стану в оперативній пам’яті), кількість копій застосунку можна змінювати без шкоди для його логіки. Нарешті, усі конфігурації, зокрема дані для підключення до бази даних, передаються через змінні середовища, що спрощує управління і масштабування.
Нижче наведено детальне пояснення як саме було виконано масштабування:
Після завершення розробки бекенду на Java Spring, я переходжу до етапу збірки застосунку. Для цього виконую команду mvnw clean package -DskipTests, яка створює .jar файл у папці target/. Опція -DskipTests дозволяє пропустити тестування під час збірки, щоб пришвидшити процес.

 
Рисунок 1 – Успішно закінчена збірка 

Далі створюю файл Dockerfile у кореневій директорії проєкту. У цьому файлі описую, як контейнер має бути побудований. Я використовую базовий образ openjdk:21-jdk-slim, копіюю зібраний .jar файл у контейнер, і вказую команду запуску — java -jar. Нижче наведено текст Dockerfile:

 
Рисунок 2 – Вміст Dockerfile 

Після цього виконую команду docker build -t skinora-backend ., яка створює локальний Docker-образ із тегом skinora-backend на основі вказаного Dockerfile. Це дозволить запускати мій застосунок як контейнер.
- Опис навантажувальних тестів 
Навантажувальне тестування було проведене з використанням інструмента Locust, який дозволяє емулювати одночасні запити до системи та вимірювати її стійкість при зростанні кількості користувачів. У процесі тестування було змодельовано до 1000 одночасних користувачів, які надсилали запити до публічного API /api/public/products. Швидкість генерації запитів становила 25 користувачів за секунду, що дало змогу поступово збільшувати навантаження й відслідковувати поведінку сервісу.
Перед початком тестів сервіс було розгорнуто у кластері Kubernetes, і доступ до нього було забезпечено через команду kubectl port-forward. За допомогою графічного інтерфейсу Locust проводився контроль кількості запитів на секунду (RPS) та частоти помилок. Після налаштування безпеки й відкриття публічної точки доступу /api/public/products було досягнуто стабільної відповіді без помилок, що свідчить про коректну роботу системи під навантаженням.
Нижче наведено кроки для выковання завднання:
Для підготовки до розгортання у Kubernetes я створюю окрему папку з назвою k8s, у яку поміщаю YAML-файли з описами необхідних об’єктів Kubernetes. Зокрема, це можуть бути deployment.yaml, service.yaml, а також за потреби ingress.yaml. 

 
Рисунок 3 – Вміст папки k8s

Нижче наведено вміст кожного файлу:

 
Рисунок 4 – Вміст файлу postgres-pvc.yaml

Цей файл створює «місце на диску» для бази даних PostgreSQL. Воно потрібно, щоб зберігати дані навіть після перезапуску контейнера. Резервуємо 1 гігабайт памʼяті.

 
Рисунок 5 – Вміст файлу postgres-deployment.yaml

Цей файл запускає контейнер з базою даних PostgreSQL. Ми вказуємо:
-	яку версію використовувати (postgres:15),
-	які логін, пароль і назву бази встановити,
-	 куди зберігати дані

 
Рисунок 6 – Вміст файлу postgres-service.yaml

Цей файл дозволяє іншим частинам програми звертатися до бази даних. Він відкриває доступ до PostgreSQL всередині Kubernetes за портом 5432.
 
Рисунок 7 – Вміст файлу deployment.yaml

Цей файл запускає основну програму — бекенд skinora-backend. Ми вказуємо, на якому порту вона працює (8080) та як підключатися до бази даних (адреса, логін, пароль).

 
Рисунок 8 – Вміст файлу service.yaml

Цей файл відкриває доступ до бекенду ззовні. Коли користувач переходить на сайт, запит йде на порт 80, а далі перенаправляється на 8080 всередині контейнера.
Нижче наведено набір команд kubectl apply -f, що послідовно створює всі необхідні компоненти Kubernetes для запуску застосунку з базою даних. Спочатку створюється postgres-pvc.yaml, який описує постійний том для зберігання даних PostgreSQL. Потім розгортається сам контейнер бази даних через postgres-deployment.yaml і відкривається доступ до нього за допомогою postgres-service.yaml. Далі застосовується deployment.yaml, який створює pod із застосунком skinora-backend, після чого запускається service.yaml для забезпечення доступу до цього пода через skinora-service. У сукупності ці ресурси формують повноцінну масштабовану інфраструктуру для вебзастосунку та бази даних.

 
Рисунок 9 – Набір команд

kubectl get pods показує, що база даних PostgreSQL та бекенд-под знаходяться в статусі Running, тобто працюють стабільно. Команда kubectl get svc перевіряє, що сервіси коректно маршрутизують трафік: база має внутрішній ClusterIP, а бекенд — зовнішній доступ через LoadBalancer.

 
Рисунок 10 – Перевірка статусу ресерсів

Створюю файл dump.sql у папці k8s. Файл dump.sql містить дамп бази даних (структуру та дані), який буде використано для заповнення таблиць PostgreSQL після запуску.
Виконую настпуну команду у консолі kubectl cp dump.sql postgres-ccfc845d6-5grsh:/dump.sql. Команда переносить файл дампу всередину pod'а з PostgreSQL. Це необхідно для того, щоб виконати імпорт бази безпосередньо зсередини контейнера, де працює сервер PostgreSQL.
Після цього виконую цю команду kubectl exec -it postgres-ccfc845d6-5grsh – bash та psql -U skinora_user -d skinora -f /dump.sql. Команда kubectl exec -it postgres-... -- bash відкриває інтерфейс командного рядка всередині pod'а. Після цього виконується команда psql -U skinora_user -d skinora -f /dump.sql, яка імпортує дамп у базу даних. Таким чином база наповнюється початковими таблицями й даними, необхідними для роботи застосунку.
	Створюю файл locustfile.py у папці skinora з наступним вмістом:
 
 
	Рисунок 11 – Вміст файлу locustfile.py

Виконую наступні команди kubectl port-forward service/skinora-service 8080:80 та  locust -H http://localhost:8080 після чого відкриваю у браузері посилання http://localhost:8089 і вводжу наступні налаштування тесту.

 
Рисунок 12 - Налаштування locust


1 pod:

 
Рисунок 13 - Результат тестування системи на 1-му поді
  
Рисунок 14 - Результат тестування системи на 1-му поді
 
Рисунок 15 - Результат тестування системи на 1-му поді

	Під час навантажувального тестування на одному поді система показала стабільну роботу за умов симульованих 1200 користувачів. Кількість запитів утримувалася на рівні приблизно 433 запити в секунду (RPS) без жодної помилки або відмови, що свідчить про високу надійність сервісу на цьому рівні навантаження. Усі запити виконувалися лише до одного ендпоінту — GET /api/public/products, що означає одновекторність тесту (всі 100% через SkinoraUser.getPatients). Середній час відповіді становив 656 мс, а медіанний — 720 мс

2 pod:
	Спочатку виконуюю команду kubectl scale deployment skinora-backend --replicas=2

 
Рисунок 16 - Результат тестування системи на 2-му поді
 
Рисунок 17 - Результат тестування системи на 2-му поді

	При навантаженні у 1200 одночасних користувачів було виконано понад 66 тисяч запитів до ендпоінту GET /api/public/products, і жоден із них не завершився з помилкою, що підтверджується нульовим значенням у колонці # Fails. Поточна продуктивність трималась на рівні 410.6 запитів/сек, що свідчить про здатність сервісу обробляти велику кількість запитів без деградації. Медіанний час відповіді становив 860 мс, середній — 782.81 мс, при мінімальному значенні 2 мс та максимумі 6958 мс. Хоча більшість запитів оброблялись швидко, максимальні значення затримки свідчать про окремі пікові просідання, які потребують додаткового аналізу
3 pod:
Виконуюю команду kubectl scale deployment skinora-backend --replicas=3

 
Рисунок 18 - Результат тестування системи на 3-му поді
  
	Рисунок 29 - Результат тестування системи на 3-му поді

	Результати навантажувального тестування для конфігурації з трьома подами демонструють помітне покращення продуктивності порівняно з одним подом. Загалом було виконано 71 415 запитів до ендпоінту GET /api/public/products, усі без жодної помилки, що свідчить про високу надійність системи при масштабуванні.
	Поточна продуктивність становить 411.2 запитів на секунду, що близьке до попередніх значень, однак середній час відповіді знизився до 618 мс, а медіанний — до 520 мс, що на сотні мілісекунд краще, ніж у попередніх тестах. 
	Максимальний час відповіді склав 5000 мс, що також нижчий, ніж у тестах з одним подом (було до 6600–6950 мс). Це вказує на те, що система не лише обробляє запити швидше, а й має меншу ймовірність виникнення пікових затримок.
- Аналіз вузьких місць
Під час проведення навантажувальних тестів із поступовим масштабуванням системи від 1 до 3 pod-ів було виявлено, що зі збільшенням кількості серверних екземплярів приріст продуктивності, зокрема RPS (requests per second), залишався незначним. У всіх конфігураціях значення RPS коливалося в межах 410–433 запитів на секунду. Це свідчить про наявність обмежувального фактора, який стримує подальше масштабування та ефективність обробки запитів.
Аналіз графіків навантаження показав, що при збільшенні кількості користувачів до 1200 система стабільно обробляла запити без збоїв, однак максимальний час відповіді навіть при трьох pod-ах сягав 5000–6950 мс. Середній час відповіді також знижувався повільно: від ~782 мс на одному поді до ~618 мс при трьох подах. Це вказує на те, що основне навантаження концентрується не на рівні окремих подів, а в точці централізованого доступу до даних.
Найбільш ймовірним вузьким місцем є база даних PostgreSQL, яка працює як окремий pod і не масштабується разом із бекендом. Усі запити до ендпоінту /api/public/products надходять одночасно з усіх backend-подів до однієї бази, що призводить до зростання затримок при навантаженні. Це підтверджується також відсутністю збільшення RPS при переході від 1 до 3 подів — система досягає межі пропускної здатності саме на рівні СУБД.
Тестування проводилося у середовищі Docker Desktop під Windows, де Kubernetes-кластер працює у віртуалізованому оточенні з обмеженим доступом до ресурсів (CPU, RAM). Це також могло впливати на затримки при високому навантаженні, оскільки кілька подів додатку й база даних запускались на одному хості.
У реальних умовах продакшн-середовища (наприклад, GKE, EKS, AKS) зазначені обмеження могли б бути частково або повністю зняті завдяки можливості горизонтального масштабування бази, використанню managed-сервісів або оптимізованих рішень для розподілу навантаження.
Таким чином, основним вузьким місцем виявилась база даних, яка обмежує масштабованість backend-частини, а в умовах локального середовища — також і апаратні ресурси хост-машини. Для покращення масштабування рекомендується оптимізувати роботу з БД, впровадити пул з’єднань, кешування, або перейти до розподіленої моделі з використанням хмарних сервісів.
Висновок: У ході виконання навантажувального тестування я ознайомилася з принципами оцінки продуктивності у середовищі Kubernetes. Навчилася запускати тести з поступовим масштабуванням кількості pod-ів, аналізувати ключові метрики, зокрема RPS, час відповіді та кількість збоїв. Здобула навички виявлення вузьких місць у системі — зокрема, зрозуміла, як централізована база даних може обмежувати ефективність масштабування, навіть якщо кількість подів зростає.
